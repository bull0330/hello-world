{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2.SKT_OpenNMT_Pytorch_실습_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bull0330/hello-world/blob/master/2_SKT_OpenNMT_Pytorch_%EC%8B%A4%EC%8A%B5_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fpgq2KISOHBo"
      },
      "source": [
        "# OpenNMT Pytorch를 이용한 기계번역 모델 만들어보기\n",
        "\n",
        "***First Go to Runtime and  change the runtime type to GPU.***\n",
        "\n",
        "\n",
        "<br>\n",
        " Copyright Park Chanjun\n",
        "<br>\n",
        " Email: bcj1210@naver.com\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aKrzegS2O1t3"
      },
      "source": [
        "# Git Clone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0-kDi11Xx5bs",
        "colab": {}
      },
      "source": [
        "#!git clone https://github.com/OpenNMT/OpenNMT-py   # pytorch 버전"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1TlIyXGzO61s"
      },
      "source": [
        "# Please install requirements.txt use by pip\n",
        "\n",
        "> Error : You must restart the runtime in order to use newly installed versions.<br>\n",
        "Solution : Click Restart Runtime => Redo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Gq-o1qtyFR0",
        "outputId": "d71f5c82-7072-4236-fc75-11ef79089940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "!pip3 install -r OpenNMT-py/requirements.txt --upgrade\n",
        "!pip3 install configargparse --upgrade"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/pytorch/text.git@master#wheel=torchtext (from -r OpenNMT-py/requirements.txt (line 4))\n",
            "  Cloning https://github.com/pytorch/text.git (to revision master) to /tmp/pip-req-build-niequjaq\n",
            "  Running command git clone -q https://github.com/pytorch/text.git /tmp/pip-req-build-niequjaq\n",
            "Requirement already up-to-date: six in /usr/local/lib/python3.6/dist-packages (from -r OpenNMT-py/requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already up-to-date: tqdm==4.30.* in /usr/local/lib/python3.6/dist-packages (from -r OpenNMT-py/requirements.txt (line 2)) (4.30.0)\n",
            "Requirement already up-to-date: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from -r OpenNMT-py/requirements.txt (line 3)) (1.2.0)\n",
            "Requirement already up-to-date: future in /usr/local/lib/python3.6/dist-packages (from -r OpenNMT-py/requirements.txt (line 5)) (0.17.1)\n",
            "Requirement already up-to-date: configargparse in /usr/local/lib/python3.6/dist-packages (from -r OpenNMT-py/requirements.txt (line 6)) (0.14.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0->-r OpenNMT-py/requirements.txt (line 4)) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0->-r OpenNMT-py/requirements.txt (line 4)) (1.16.5)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->-r OpenNMT-py/requirements.txt (line 4)) (2019.6.16)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->-r OpenNMT-py/requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->-r OpenNMT-py/requirements.txt (line 4)) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0->-r OpenNMT-py/requirements.txt (line 4)) (3.0.4)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchtext: filename=torchtext-0.4.0-cp36-none-any.whl size=53452 sha256=d79614d9cdd966459cb33291f9435e76bf70f5a4e5215265536df253634030c3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nxf09vn2/wheels/47/f9/8d/a9e397ec2629a3fd3219b2ebc3ec8b55396fd3cf55963a77a5\n",
            "Successfully built torchtext\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.4.0\n",
            "    Uninstalling torchtext-0.4.0:\n",
            "      Successfully uninstalled torchtext-0.4.0\n",
            "Successfully installed torchtext-0.4.0\n",
            "Requirement already up-to-date: configargparse in /usr/local/lib/python3.6/dist-packages (0.14.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s_4ZgPbp71Eb"
      },
      "source": [
        "# 기계번역 모델 만드는 순서\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**1.   데이터 수집**\n",
        "\n",
        "병렬 코퍼스를 수집해야합니다.\n",
        "이번 실습에서는 OpenNMT에서 제공하는 WMT 데이터를 사용합니다.\n",
        "\n",
        "**2.   정제, 병렬 코퍼스 필터링**\n",
        "\n",
        "병렬 코퍼스 필터링 (생략)\n",
        "\n",
        "\n",
        "**3. 서브워드 분리**\n",
        "\n",
        "BPE를 사용\n",
        "\n",
        "\n",
        "**4. 학습**\n",
        "\n",
        "GPU를 이용한 Transformer 훈련\n",
        "\n",
        "\n",
        "**5. 번역**\n",
        "\n",
        "모델을 이용한 번역\n",
        "\n",
        "\n",
        "**6. Detokenization**\n",
        "\n",
        "디토큰\n",
        "\n",
        "\n",
        "**7. 점수계산**\n",
        "\n",
        "BLEU 점수 계산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aTBNfRgW-WvJ"
      },
      "source": [
        "# Subword Tokenization\n",
        "\n",
        "We use Byte Pair Encoding for Subword Tokenization\n",
        "\n",
        "https://www.aclweb.org/anthology/P16-1162\n",
        "\n",
        "i => input<br>\n",
        "o ==> Output(*.code)<br>\n",
        "s ==> Symbol<br>\n",
        "\n",
        "learn_bpe ==> make code<br>\n",
        "apply_bpe ==> apply subwordTokenization<br>\n",
        "\n",
        "src-train, src-val,test ==> Need to apply src.code<br>\n",
        "tgt-train,tgt-val ==> Need to apply tgt.code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ASorEhAu-kdM",
        "colab": {}
      },
      "source": [
        "!python3 OpenNMT-py/tools/learn_bpe.py -i OpenNMT-py/data/src-train.txt -o OpenNMT-py/data/src.code -s 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rBNAu8tR_GcV",
        "colab": {}
      },
      "source": [
        "!python3 OpenNMT-py/tools/learn_bpe.py -i OpenNMT-py/data/tgt-train.txt -o OpenNMT-py/data/tgt.code -s 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hB5FdD-H_H59",
        "colab": {}
      },
      "source": [
        "!python3 OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i OpenNMT-py/data/src-train.txt -o OpenNMT-py/data/src-train-bpe.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UaherUkX_IBg",
        "colab": {}
      },
      "source": [
        "!python3 OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i OpenNMT-py/data/src-val.txt -o OpenNMT-py/data/src-val-bpe.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gz7Xu72Y_mWW",
        "colab": {}
      },
      "source": [
        "!python3 OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/src.code -i OpenNMT-py/data/src-test.txt -o OpenNMT-py/data/src-test-bpe.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LSGaSYgq_nmd",
        "colab": {}
      },
      "source": [
        "!python3 OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/tgt.code -i OpenNMT-py/data/tgt-train.txt -o OpenNMT-py/data/tgt-train-bpe.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I7n68i95_nuJ",
        "colab": {}
      },
      "source": [
        "!python3 OpenNMT-py/tools/apply_bpe.py -c OpenNMT-py/data/tgt.code -i OpenNMT-py/data/tgt-val.txt -o OpenNMT-py/data/tgt-val-bpe.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FknMbLeePeoQ"
      },
      "source": [
        "# **Preprocess the data**\n",
        "\n",
        "We will be working with some example data in data/ folder.\n",
        "\n",
        "The data consists of parallel source (src) and target (tgt) data containing one sentence per line with tokens separated by a space:\n",
        "\n",
        "1. src-train.txt\n",
        "\n",
        "2. tgt-train.txt\n",
        "\n",
        "3. src-val.txt\n",
        "\n",
        "4. tgt-val.txt\n",
        "\n",
        "\n",
        "Train data and validataion data are required for machine translation training.\n",
        "\n",
        "Validation files are required and used to evaluate the convergence of the training. It usually contains no more than 5000 sentences.\n",
        "\n",
        "\n",
        "> If you think about it briefly, you can specify the path of train data and validation data, and specify the path and name to save in -save_data.\n",
        "\n",
        "> If you want to set vocab size add below command\n",
        "<br>\n",
        "-src_vocab_size 32000 -tgt_vocab_size 32000\n",
        "\n",
        "The vocab size is usually 32000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7DrdI_6l0Kvw",
        "outputId": "bf07cd8c-8c38-49e0-8e49-9d0089464e22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python3 OpenNMT-py/preprocess.py -train_src OpenNMT-py/data/src-train-bpe.txt -train_tgt OpenNMT-py/data/tgt-train-bpe.txt -valid_src OpenNMT-py/data/src-val-bpe.txt -valid_tgt OpenNMT-py/data/tgt-val-bpe.txt -save_data OpenNMT-py/data/demo -src_vocab_size 32000 -tgt_vocab_size 32000"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please backup existing pt files: OpenNMT-py/data/demo.train*.pt, to avoid overwriting them!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z8wQov27R004"
      },
      "source": [
        "# **Train the data(Transformer)**\n",
        "\n",
        "https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf\n",
        "\n",
        "\n",
        "> If you get GPU-related errors, try halving batch_size\n",
        "\n",
        "**Below is the full command, and if you want to know more about it, search about Transformer.**\n",
        "\n",
        "!python OpenNMT-py/train.py -data OpenNMT-py/data/demo -save_model OpenNMT-py/data/model/model -layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 -encoder_type transformer -decoder_type transformer -position_encoding -train_steps 200000 -max_generator_batches 2 -dropout 0.1 -batch_size 4096 -batch_type tokens -normalization tokens -accum_count 2 -optim adam -adam_beta2 0.998 -decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 -param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 -world_size 1 -gpu_rank 0  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YH1fS8F2VAuz",
        "outputId": "a9bf6ad9-e962-424b-db11-d76cbf7bed13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Sep 12 02:55:57 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZdTjS0bTSVLk",
        "outputId": "f8ab7fbb-f4bb-425f-c7b8-8392309cc219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 OpenNMT-py/train.py -data OpenNMT-py/data/demo -save_model OpenNMT-py/data/model/model -layers 6 -rnn_size 512 -word_vec_size 512 -transformer_ff 2048 -heads 8 -encoder_type transformer -decoder_type transformer -position_encoding -train_steps 200000 -max_generator_batches 2 -dropout 0.1 -batch_size 4096 -batch_type tokens -normalization tokens -accum_count 2 -optim adam -adam_beta2 0.998 -decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 -param_init_glorot -label_smoothing 0.1 -valid_steps 1000 -save_checkpoint_steps 1000 -world_size 1 -gpu_rank 0  # 오래걸리"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2019-09-12 02:56:00,743 INFO]  * src vocab size = 9739\n",
            "[2019-09-12 02:56:00,743 INFO]  * tgt vocab size = 10034\n",
            "[2019-09-12 02:56:00,743 INFO] Building model...\n",
            "[2019-09-12 02:56:04,343 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(9739, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(10034, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding(\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (relu): ReLU()\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (generator): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=10034, bias=True)\n",
            "    (1): Cast()\n",
            "    (2): LogSoftmax()\n",
            "  )\n",
            ")\n",
            "[2019-09-12 02:56:04,357 INFO] encoder: 23901696\n",
            "[2019-09-12 02:56:04,357 INFO] decoder: 35510066\n",
            "[2019-09-12 02:56:04,357 INFO] * number of parameters: 59411762\n",
            "[2019-09-12 02:56:04,361 INFO] Starting training on GPU: [0]\n",
            "[2019-09-12 02:56:04,361 INFO] Start training loop and validate every 1000 steps...\n",
            "[2019-09-12 02:56:04,361 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 02:56:04,450 INFO] number of examples: 8868\n",
            "[2019-09-12 02:57:18,898 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 02:57:19,045 INFO] number of examples: 8868\n",
            "[2019-09-12 02:57:30,752 INFO] Step 50/200000; acc:   2.35; ppl: 2532.66; xent: 7.84; lr: 0.00001; 2842/3211 tok/s;     86 sec\n",
            "[2019-09-12 02:58:33,382 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 02:58:33,524 INFO] number of examples: 8868\n",
            "[2019-09-12 02:58:57,508 INFO] Step 100/200000; acc:   4.62; ppl: 1782.68; xent: 7.49; lr: 0.00001; 2910/3299 tok/s;    173 sec\n",
            "[2019-09-12 02:59:47,749 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 02:59:47,915 INFO] number of examples: 8868\n",
            "[2019-09-12 03:00:23,668 INFO] Step 150/200000; acc:   5.19; ppl: 1387.62; xent: 7.24; lr: 0.00002; 2909/3287 tok/s;    259 sec\n",
            "[2019-09-12 03:01:02,233 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:01:02,321 INFO] number of examples: 8868\n",
            "[2019-09-12 03:01:50,443 INFO] Step 200/200000; acc:   6.06; ppl: 1041.69; xent: 6.95; lr: 0.00002; 2908/3285 tok/s;    346 sec\n",
            "[2019-09-12 03:02:16,643 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:02:16,784 INFO] number of examples: 8868\n",
            "[2019-09-12 03:03:17,107 INFO] Step 250/200000; acc:   8.23; ppl: 766.33; xent: 6.64; lr: 0.00003; 2897/3306 tok/s;    433 sec\n",
            "[2019-09-12 03:03:30,972 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:03:31,124 INFO] number of examples: 8868\n",
            "[2019-09-12 03:04:43,770 INFO] Step 300/200000; acc:   9.50; ppl: 601.57; xent: 6.40; lr: 0.00004; 2909/3291 tok/s;    519 sec\n",
            "[2019-09-12 03:04:45,328 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:04:45,496 INFO] number of examples: 8868\n",
            "[2019-09-12 03:05:59,778 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:05:59,872 INFO] number of examples: 8868\n",
            "[2019-09-12 03:06:10,083 INFO] Step 350/200000; acc:  10.03; ppl: 531.84; xent: 6.28; lr: 0.00004; 2850/3212 tok/s;    606 sec\n",
            "[2019-09-12 03:07:14,179 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:07:14,315 INFO] number of examples: 8868\n",
            "[2019-09-12 03:07:36,642 INFO] Step 400/200000; acc:  10.36; ppl: 501.59; xent: 6.22; lr: 0.00005; 2891/3272 tok/s;    692 sec\n",
            "[2019-09-12 03:08:28,658 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:08:28,810 INFO] number of examples: 8868\n",
            "[2019-09-12 03:09:02,690 INFO] Step 450/200000; acc:  11.55; ppl: 466.03; xent: 6.14; lr: 0.00006; 2895/3293 tok/s;    778 sec\n",
            "[2019-09-12 03:09:43,239 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:09:43,403 INFO] number of examples: 8868\n",
            "[2019-09-12 03:10:29,751 INFO] Step 500/200000; acc:  11.93; ppl: 435.38; xent: 6.08; lr: 0.00006; 2906/3267 tok/s;    865 sec\n",
            "[2019-09-12 03:10:57,769 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:10:57,857 INFO] number of examples: 8868\n",
            "[2019-09-12 03:11:56,306 INFO] Step 550/200000; acc:  12.39; ppl: 385.37; xent: 5.95; lr: 0.00007; 2905/3316 tok/s;    952 sec\n",
            "[2019-09-12 03:12:11,932 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:12:12,075 INFO] number of examples: 8868\n",
            "[2019-09-12 03:13:22,950 INFO] Step 600/200000; acc:  12.97; ppl: 321.39; xent: 5.77; lr: 0.00007; 2935/3325 tok/s;   1039 sec\n",
            "[2019-09-12 03:13:26,081 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:13:26,235 INFO] number of examples: 8868\n",
            "[2019-09-12 03:14:40,141 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:14:40,315 INFO] number of examples: 8868\n",
            "[2019-09-12 03:14:48,783 INFO] Step 650/200000; acc:  13.57; ppl: 275.04; xent: 5.62; lr: 0.00008; 2850/3220 tok/s;   1124 sec\n",
            "[2019-09-12 03:15:54,270 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:15:54,359 INFO] number of examples: 8868\n",
            "[2019-09-12 03:16:14,881 INFO] Step 700/200000; acc:  14.07; ppl: 246.11; xent: 5.51; lr: 0.00009; 2905/3279 tok/s;   1211 sec\n",
            "[2019-09-12 03:17:08,309 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:17:08,453 INFO] number of examples: 8868\n",
            "[2019-09-12 03:17:40,374 INFO] Step 750/200000; acc:  14.81; ppl: 219.07; xent: 5.39; lr: 0.00009; 2908/3308 tok/s;   1296 sec\n",
            "[2019-09-12 03:18:22,358 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:18:22,511 INFO] number of examples: 8868\n",
            "[2019-09-12 03:19:06,946 INFO] Step 800/200000; acc:  15.25; ppl: 200.29; xent: 5.30; lr: 0.00010; 2938/3302 tok/s;   1383 sec\n",
            "[2019-09-12 03:19:36,432 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:19:36,613 INFO] number of examples: 8868\n",
            "[2019-09-12 03:20:33,255 INFO] Step 850/200000; acc:  15.14; ppl: 188.36; xent: 5.24; lr: 0.00011; 2909/3320 tok/s;   1469 sec\n",
            "[2019-09-12 03:20:50,553 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:20:50,653 INFO] number of examples: 8868\n",
            "[2019-09-12 03:21:59,650 INFO] Step 900/200000; acc:  16.26; ppl: 167.23; xent: 5.12; lr: 0.00011; 2914/3307 tok/s;   1555 sec\n",
            "[2019-09-12 03:22:04,687 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:22:04,875 INFO] number of examples: 8868\n",
            "[2019-09-12 03:23:18,994 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:23:19,149 INFO] number of examples: 8868\n",
            "[2019-09-12 03:23:25,726 INFO] Step 950/200000; acc:  17.65; ppl: 146.15; xent: 4.98; lr: 0.00012; 2842/3208 tok/s;   1641 sec\n",
            "[2019-09-12 03:24:33,097 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:24:33,269 INFO] number of examples: 8868\n",
            "[2019-09-12 03:24:51,963 INFO] Step 1000/200000; acc:  18.03; ppl: 137.22; xent: 4.92; lr: 0.00012; 2914/3299 tok/s;   1728 sec\n",
            "[2019-09-12 03:24:51,965 INFO] Loading dataset from OpenNMT-py/data/demo.valid.0.pt\n",
            "[2019-09-12 03:24:52,004 INFO] number of examples: 3000\n",
            "[2019-09-12 03:25:13,253 INFO] Validation perplexity: 683.171\n",
            "[2019-09-12 03:25:13,254 INFO] Validation accuracy: 9.30637\n",
            "[2019-09-12 03:25:13,323 INFO] Saving checkpoint OpenNMT-py/data/model/model_step_1000.pt\n",
            "[2019-09-12 03:26:12,547 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:26:12,736 INFO] number of examples: 8868\n",
            "[2019-09-12 03:26:42,970 INFO] Step 1050/200000; acc:  18.43; ppl: 126.57; xent: 4.84; lr: 0.00013; 2241/2540 tok/s;   1839 sec\n",
            "[2019-09-12 03:27:26,674 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:27:26,769 INFO] number of examples: 8868\n",
            "[2019-09-12 03:28:09,291 INFO] Step 1100/200000; acc:  19.16; ppl: 116.89; xent: 4.76; lr: 0.00014; 2933/3301 tok/s;   1925 sec\n",
            "[2019-09-12 03:28:40,695 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:28:40,860 INFO] number of examples: 8868\n",
            "[2019-09-12 03:29:35,610 INFO] Step 1150/200000; acc:  19.97; ppl: 107.79; xent: 4.68; lr: 0.00014; 2912/3317 tok/s;   2011 sec\n",
            "[2019-09-12 03:29:54,749 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:29:54,937 INFO] number of examples: 8868\n",
            "[2019-09-12 03:31:01,998 INFO] Step 1200/200000; acc:  21.09; ppl: 96.19; xent: 4.57; lr: 0.00015; 2917/3311 tok/s;   2098 sec\n",
            "[2019-09-12 03:31:08,866 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:31:09,111 INFO] number of examples: 8868\n",
            "[2019-09-12 03:32:23,173 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:32:23,274 INFO] number of examples: 8868\n",
            "[2019-09-12 03:32:28,261 INFO] Step 1250/200000; acc:  22.41; ppl: 84.86; xent: 4.44; lr: 0.00015; 2855/3225 tok/s;   2184 sec\n",
            "[2019-09-12 03:33:37,406 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:33:37,604 INFO] number of examples: 8868\n",
            "[2019-09-12 03:33:54,797 INFO] Step 1300/200000; acc:  23.27; ppl: 77.40; xent: 4.35; lr: 0.00016; 2901/3276 tok/s;   2270 sec\n",
            "[2019-09-12 03:34:51,797 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:34:51,985 INFO] number of examples: 8868\n",
            "[2019-09-12 03:35:20,623 INFO] Step 1350/200000; acc:  24.68; ppl: 68.67; xent: 4.23; lr: 0.00017; 2900/3295 tok/s;   2356 sec\n",
            "[2019-09-12 03:36:06,104 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:36:06,307 INFO] number of examples: 8868\n",
            "[2019-09-12 03:36:47,317 INFO] Step 1400/200000; acc:  26.24; ppl: 60.42; xent: 4.10; lr: 0.00017; 2914/3280 tok/s;   2443 sec\n",
            "[2019-09-12 03:37:20,517 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:37:20,622 INFO] number of examples: 8868\n",
            "[2019-09-12 03:38:13,848 INFO] Step 1450/200000; acc:  27.49; ppl: 53.31; xent: 3.98; lr: 0.00018; 2903/3304 tok/s;   2529 sec\n",
            "[2019-09-12 03:38:34,830 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:38:35,035 INFO] number of examples: 8868\n",
            "[2019-09-12 03:39:40,725 INFO] Step 1500/200000; acc:  29.17; ppl: 46.60; xent: 3.84; lr: 0.00019; 2910/3306 tok/s;   2616 sec\n",
            "[2019-09-12 03:39:49,251 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:39:49,485 INFO] number of examples: 8868\n",
            "[2019-09-12 03:41:03,611 INFO] Loading dataset from OpenNMT-py/data/demo.train.0.pt\n",
            "[2019-09-12 03:41:03,869 INFO] number of examples: 8868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MMf27BpGWpn7"
      },
      "source": [
        "# **Translate**\n",
        "\n",
        "Now that you have your model, you can start translating.\n",
        "\n",
        "-model ==> Setting your model\n",
        "\n",
        "Output predictions into pred.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uqz9Iu7pW4Bq",
        "colab": {}
      },
      "source": [
        "!python3 OpenNMT-py/translate.py -model OpenNMT-py/data/model/model_step_1000.pt -src OpenNMT-py/data/src-val.txt -output OpenNMT-py/data/pred.txt -replace_unk -verbose -gpu 0  # pred.txt 가 여기서 만들어짐"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gjG2ILxtGQ5U"
      },
      "source": [
        "# Detokenization\n",
        "\n",
        "Even after the translation process is finished, it is still in a segment, so it is different from the actual sentence structure used by real people. Thus, when you perform a detoxification process, it is returned in the form of the actual sentence.\n",
        "\n",
        "We Use \"sed\" for BPE Detokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "74sox8UmGcbc",
        "colab": {}
      },
      "source": [
        "!sed -i \"s/@@ //g\"  OpenNMT-py/data/pred.txt  #일종의 정규표현식. \"@@ \" 부분을 공백으로 처리해서 detokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gCHeu1YFGngg"
      },
      "source": [
        "# Evaluation Using BLEU\n",
        "\n",
        "Quantitative evaluation is performed on the sentence thus obtained. BLEU is a quantitative evaluation method for machine translation. You can see which model is superior by comparing it to the BLEU score you are comparing.\n",
        "\n",
        "https://www.aclweb.org/anthology/P02-1040"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8gpcnSSTG0Kg",
        "colab": {}
      },
      "source": [
        "!perl  OpenNMT-py/tools/multi-bleu.perl OpenNMT-py/data/tgt-val.txt < OpenNMT-py/data/pred.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PfAgvxNCXTo6"
      },
      "source": [
        "If you have Any Question Please Email to  \"bcj1210@naver.com\""
      ]
    }
  ]
}